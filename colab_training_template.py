"""
üìù Code √† ajouter √† votre notebook Google Colab pour l'entra√Ænement du mod√®le

Ajoutez ces cellules √† la fin de votre notebook maize_yield_prediction.ipynb
"""

# ============================================================================
# CELLULE 1 : Installer les packages n√©cessaires (si pas d√©j√† fait)
# ============================================================================
"""
!pip install scikit-learn joblib pandas numpy
"""

# ============================================================================
# CELLULE 2 : Fonction de sauvegarde avec m√©tadonn√©es
# ============================================================================
"""
import joblib
import json
from datetime import datetime
import sklearn
import pandas as pd
import numpy as np
import sys

def save_model_with_metadata(model, input_columns, model_path='yield_prediction_model.pkl', 
                             metadata_path='model_metadata.json'):
    '''
    Sauvegarde un mod√®le avec ses m√©tadonn√©es de version
    '''
    
    # Sauvegarder le mod√®le
    joblib.dump(model, model_path)
    joblib.dump(input_columns, 'model_input_columns.pkl')
    
    # Cr√©er les m√©tadonn√©es
    metadata = {
        'model_version': '1.0.0',
        'created_date': datetime.now().isoformat(),
        'python_version': f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        'package_versions': {
            'scikit-learn': sklearn.__version__,
            'joblib': joblib.__version__,
            'pandas': pd.__version__,
            'numpy': np.__version__
        },
        'input_columns': input_columns,
        'model_type': type(model).__name__
    }
    
    # Sauvegarder les m√©tadonn√©es
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Mod√®le sauvegard√© : {model_path}")
    print(f"‚úÖ M√©tadonn√©es sauvegard√©es : {metadata_path}")
    print(f"\\nVersions enregistr√©es :")
    for pkg, version in metadata['package_versions'].items():
        print(f"  - {pkg}: {version}")
    
    return metadata
"""

# ============================================================================
# CELLULE 3 : Sauvegarder le mod√®le apr√®s l'entra√Ænement
# ============================================================================
"""
# Apr√®s avoir entra√Æn√© votre mod√®le (remplacez 'model' et 'X' par vos variables)
# model = votre_pipeline_ou_modele
# X = votre_dataframe_de_features

# Sauvegarder avec m√©tadonn√©es
metadata = save_model_with_metadata(
    model=model,
    input_columns=X.columns.tolist()
)

# Afficher les m√©tadonn√©es
print("\\n" + "="*50)
print("M√âTADONN√âES DU MOD√àLE")
print("="*50)
import json
print(json.dumps(metadata, indent=2))
"""

# ============================================================================
# CELLULE 4 : T√©l√©charger les fichiers depuis Colab
# ============================================================================
"""
# T√©l√©charger les fichiers
from google.colab import files

print("T√©l√©chargement des fichiers...")
files.download('yield_prediction_model.pkl')
files.download('model_input_columns.pkl')
files.download('model_metadata.json')

print("‚úÖ Tous les fichiers ont √©t√© t√©l√©charg√©s!")
print("\\nüìÅ Placez ces 3 fichiers dans le dossier 'models/' de votre application Streamlit")
"""

# ============================================================================
# CELLULE 5 : Cr√©er un fichier requirements.txt pour Colab
# ============================================================================
"""
# Enregistrer les versions utilis√©es pour l'entra√Ænement
import sklearn, joblib, pandas, numpy, tensorflow

versions_text = f'''# Versions utilis√©es pour l'entra√Ænement du mod√®le
# G√©n√©r√© le {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

scikit-learn=={sklearn.__version__}
joblib=={joblib.__version__}
pandas=={pandas.__version__}
numpy=={numpy.__version__}
'''

# Si vous utilisez TensorFlow
try:
    versions_text += f'tensorflow=={tensorflow.__version__}\\n'
except:
    pass

with open('requirements_training.txt', 'w') as f:
    f.write(versions_text)

print(versions_text)
print("\\n‚úÖ Fichier requirements_training.txt cr√©√©")

# T√©l√©charger
files.download('requirements_training.txt')
"""

# ============================================================================
# EXEMPLE COMPLET D'UTILISATION
# ============================================================================
"""
# Voici un exemple complet de la fin de votre notebook :

# 1. Entra√Æner le mod√®le
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

model = Pipeline([
    ('scaler', StandardScaler()),
    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
])

model.fit(X_train, y_train)

# 2. √âvaluer le mod√®le
from sklearn.metrics import r2_score, mean_absolute_error

y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print(f"R¬≤ Score: {r2:.3f}")
print(f"MAE: {mae:.2f}")

# 3. Sauvegarder avec m√©tadonn√©es
metadata = save_model_with_metadata(
    model=model,
    input_columns=X.columns.tolist()
)

# Ajouter les m√©triques aux m√©tadonn√©es
metadata['performance'] = {
    'r2_score': float(r2),
    'mae': float(mae)
}

with open('model_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)

# 4. T√©l√©charger tous les fichiers
from google.colab import files
files.download('yield_prediction_model.pkl')
files.download('model_input_columns.pkl')
files.download('model_metadata.json')
"""

print(__doc__)
